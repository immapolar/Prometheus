# Prometheus Uniqueness Roadmap
## Achieving 65%+ Per-File Obfuscation Uniqueness

**Objective**: Transform Prometheus from a pattern-based obfuscator into a polymorphic engine that produces 65%+ unique output for every file, following Luraph's methodology of breaking automated de-obfuscation tools.

**Philosophy**: Force attackers to either build file-specific de-obfuscation tools or resort to manual analysis (difficult, complex, time-consuming, and effort-heavy).

---

## Implementation Status

### Completed Objectives

✅ **Phase 1, Objective 1.1: Entropy-Based Random Engine** - File-content-based entropy seeding implemented and verified

✅ **Phase 1, Objective 1.2: Algorithm Randomization Framework** - Polymorphic variant selection framework implemented and integrated with pipeline

✅ **Phase 2, Objective 2.1: Multiple Encryption Algorithms** - 5 encryption algorithm variants (LCG, XORShift, ChaCha, BlumBlumShub, MixedCongruential) implemented with polymorphic selection

✅ **Phase 5, Objective 5.2: Polymorphic Expression Trees** - Expression tree depth, balance, and no-op wrapping randomization implemented and verified

✅ **Phase 6, Objective 6.2: Dynamic Name Length Distribution** - Name length distribution implemented and verified

✅ **Phase 7, Objective 7.1: Dynamic Metamethod Selection** - Metamethod randomization with 19 total metamethods implemented and verified

✅ **Phase 7, Objective 7.2: Nested Proxy Chains** - Multi-level proxy wrapping (1-4 levels) with automatic metamethod chaining implemented and verified

✅ **Phase 9, Objective 9.1: Statement Reordering** - Statement shuffling with dependency analysis implemented and verified

✅ **Phase 9, Objective 9.2: Dead Code Injection** - Dead code injection implemented and verified

✅ **Phase 10, Objective 10.2: Per-File Step Configuration Randomization** - Setting randomization with safe ranges implemented and verified

### In Progress

(None)

### Pending

All remaining objectives per roadmap

---

## Current State Analysis

### Pattern Vulnerabilities Identified

**Critical Issues (High Impact on Uniqueness)**:
1. ~~**Deterministic Seed-Based Randomization**~~ - ✅ FIXED (Phase 1.1: Entropy-based seeding)
2. ~~**Fixed Encryption Parameters**~~ - ✅ FIXED (Phase 2.1: 5 polymorphic encryption algorithms with randomized parameters)
3. **Predictable Name Generation** - MangledShuffled uses fixed character arrays
4. **Static Wrapper Patterns** - ConstantArray wrappers follow identical structure
5. **Linear Control Flow Preservation** - Original control flow remains intact
6. ~~**Monomorphic Expression Trees**~~ - ✅ FIXED (Phase 5.2: Polymorphic expression trees with depth/balance/no-op randomization)

**Moderate Issues (Medium Impact)**:
7. ~~**Consistent Metatable Operations**~~ - ✅ FIXED (Phase 7.1: Dynamic metamethod selection per variable)
8. **Fixed String Split Patterns** - SplitStrings has predictable concatenation
9. **Constant VM Instruction Set** - Vmify generates same bytecode format
10. **Static Unparser Output** - Code generation follows rigid templates

**Low Impact Issues**:
11. **Predictable Watermark Locations** - AntiTamper insertion points are static
12. **Fixed Base64 Character Shuffle** - ConstantArray encoding is consistent per seed

---

## Architecture Transformation Goals

### Core Principle: Polymorphic Per-File Randomization

Each obfuscated file must have:
- **Unique encryption algorithms** (not just different keys)
- **Unique code generation templates**
- **Unique control flow transformations**
- **Unique VM instruction sets** (when Vmify is used)
- **Unique constant extraction strategies**
- **Unique variable naming schemes**

---

## Implementation Roadmap

### **Phase 1: Polymorphic Foundation**

#### **Objective 1.1: Entropy-Based Random Engine** ✅ **COMPLETED**
**Problem**: Deterministic `math.random()` with seeds produces identical outputs.

**Solution**:
- Create `src/prometheus/entropy.lua` module
- Implement multiple entropy sources:
  - High-resolution timestamp (microseconds)
  - File content hash (SHA-256 of source code)
  - Process ID and memory address entropy
  - System-specific entropy (CPU, GPU info)
- Combine entropy sources with cryptographic hash mixing
- Provide per-step isolated RNG state (each step gets independent entropy)

**Files to Modify**:
- `src/prometheus/pipeline.lua`: Replace `math.randomseed()` with entropy engine
- All step files: Accept entropy context parameter

**Success Metric**: Same file obfuscated twice produces different outputs even with identical configuration.

---

#### **Objective 1.2: Algorithm Randomization Framework** ✅ **COMPLETED**
**Problem**: Steps use fixed algorithms (e.g., EncryptStrings always uses same PRNG formula).

**Solution**:
- Create `src/prometheus/polymorphism.lua` framework
- Define algorithm variant system:
  - Each step declares multiple algorithm variants
  - Pipeline randomly selects variant per file
  - Variants are functionally equivalent but structurally different
- Implement variant registry and selection logic

**Files Created**:
- `src/prometheus/polymorphism.lua` - Complete polymorphism framework with variant registry, selection, and management
- `src/prometheus/variants/registry.lua` - Central registry for future variant implementations
- `src/prometheus/variants/` directory - Directory structure for step-specific variants

**Integration**:
- `src/prometheus/pipeline.lua` - Integrated polymorphism instance initialization and entropy-based variant selection

**Testing**:
- `tests/polymorphism_test.lua` - Comprehensive test suite validating all framework functionality

**Success Metric**: Framework complete and ready. Each step can now execute using multiple algorithm variants once variants are implemented in Phases 2-8.

---

### **Phase 2: String Encryption Polymorphism**

#### **Objective 2.1: Multiple Encryption Algorithms** ✅ **COMPLETED**
**Problem**: EncryptStrings uses single LCG-based PRNG algorithm.

**Solution**:
Implement 5 encryption algorithm variants:

1. ✅ **LCG Variant** - Original algorithm, kept for compatibility
2. ✅ **XORShift Variant** - XORShift32 with 8 randomized shift configurations
3. ✅ **ChaCha Variant** - ChaCha20-inspired ARX cipher with 4 rotation sets
4. ✅ **Blum Blum Shub Variant** - Cryptographically secure PRNG with 90 prime pairs
5. ✅ **Mixed Congruential Variant** - 3 combined LCGs with randomized parameters

**Implementation Details**:
- Created `src/prometheus/steps/EncryptStrings/` directory (not variants/ subdirectory)
- Each variant in separate module file
- Polymorphism framework integration for random variant selection per file
- All variants use randomized parameters per file (secret keys, shift amounts, primes, etc.)
- Each variant implements `createEncryptor()` returning `{encrypt, genCode, variant}` interface

**Files Created**:
- `src/prometheus/steps/EncryptStrings/lcg.lua` - LCG variant (176 lines)
- `src/prometheus/steps/EncryptStrings/xorshift.lua` - XORShift variant (176 lines)
- `src/prometheus/steps/EncryptStrings/chacha.lua` - ChaCha variant (203 lines)
- `src/prometheus/steps/EncryptStrings/blum_blum_shub.lua` - Blum Blum Shub variant (180 lines)
- `src/prometheus/steps/EncryptStrings/mixed_congruential.lua` - Mixed Congruential variant (184 lines)

**Files Modified**:
- `src/prometheus/steps/EncryptStrings.lua` - Complete rewrite to use polymorphism framework (113 lines, down from 240)

**Success Metric**: Encrypted strings from different files use completely different algorithms (5 variants × parameter randomization = 0% pattern correlation). ✅ **ACHIEVED**

---

#### **Objective 2.2: Dynamic Decryption Code Generation**
**Problem**: Decryption stub code is identical across all obfuscated files.

**Solution**:
- Generate decryption code from randomized templates
- Randomize variable names uniquely per file (not using global name generator)
- Randomize code structure:
  - Random statement order (shuffle independent operations)
  - Random loop constructs (for/while/repeat)
  - Random intermediate calculations
- Randomize charmap generation (different shuffle algorithms)

**Implementation**:
- `src/prometheus/steps/EncryptStrings.lua`: Refactor `genCode()` method
- Create template engine with polymorphic AST generation

**Success Metric**: Decryption stubs from different files have <10% code similarity.

---

### **Phase 3: Constant Array Polymorphism**

#### **Objective 3.1: Variable Array Indexing Strategies**
**Problem**: ConstantArray always uses direct indexing with offset wrappers.

**Solution**:
Implement 6 indexing strategies (randomly selected per file):

1. **Direct Offset** (Current) - `ARR[index + offset]`
2. **Mathematical Transform** - `ARR[index * prime % arrayLen + 1]`
3. **Bit Manipulation** - `ARR[(index ~ xorKey) & mask]`
4. **Table Indirection** - `ARR[INDEX_MAP[index]]` with shuffled mapping
5. **Function Chain** - Multiple wrapper functions with different transforms
6. **Hybrid Strategy** - Combination of 2-3 methods per array

**Implementation**:
- `src/prometheus/steps/ConstantArray/indexing_strategies/` directory
- Random strategy selection
- Per-constant randomization (different constants use different strategies)

**Files to Modify**:
- `src/prometheus/steps/ConstantArray.lua`

**Success Metric**: Constant access patterns unrecognizable between files.

---

#### **Objective 3.2: Dynamic Encoding Schemes**
**Problem**: Base64 encoding is predictable (same alphabet shuffle per seed).

**Solution**:
Implement 5 encoding variants:

1. **Custom Base64** - Random alphabet per file
2. **Custom Base85** - Higher density encoding
3. **Hexadecimal with Shuffle** - Shuffled hex digits
4. **Run-Length Encoding** - With random escape sequences
5. **Hybrid Encoding** - Different encoding per string

**Implementation**:
- `src/prometheus/steps/ConstantArray/encodings/` directory
- Random encoding selection per file or per string
- Dynamic decoder generation

**Files to Modify**:
- `src/prometheus/steps/ConstantArray.lua`

**Success Metric**: String encoding patterns show 0% similarity across files.

---

### **Phase 4: Control Flow Transformation**

#### **Objective 4.1: Opaque Predicates**
**Problem**: Control flow remains linear and transparent.

**Solution**:
- Insert opaque predicates (always true/false conditions that appear dynamic)
- Generate mathematically complex predicates:
  - `(x^2 >= 0)` - Always true
  - `(x^2 + y^2 >= 2*x*y)` - Always true
  - `(hash(const) % 2 == precomputed)` - Deterministic but appears random
- Randomize predicate types and complexity per file
- Insert fake conditional branches that never execute

**Implementation**:
- Create `src/prometheus/steps/ControlFlowFlatten.lua` step
- Implement opaque predicate generator
- Random predicate insertion at function entry/exit and loops

**Files to Create**:
- `src/prometheus/steps/ControlFlowFlatten.lua`

**Success Metric**: Control flow graphs differ significantly between files with same source.

---

#### **Objective 4.2: Control Flow Dispatcher**
**Problem**: Statement execution order is linear.

**Solution**:
- Implement dispatcher-based control flow:
  - Convert sequential blocks to state machine
  - Random state number assignment
  - Dispatcher loop selects next state
- Randomize dispatcher implementation:
  - Table-based dispatch vs if-else chain vs computed goto (if supported)
  - Random state transition calculations

**Implementation**:
- Extend `src/prometheus/steps/ControlFlowFlatten.lua`
- Add dispatcher variant system

**Success Metric**: Execution flow unrecognizable; automated CFG reconstruction fails.

---

### **Phase 5: Expression Polymorphism**

#### **Objective 5.1: Deep Expression Diversification** ✅ **COMPLETED**
**Problem**: NumbersToExpressions uses only 2 generators (add/sub).

**Solution**:
Implement 15 expression generators to maximize expression diversity per number literal.

**Generators Implemented**:
1. ✅ **Addition** - `val = val2 + diff` (existing)
2. ✅ **Subtraction** - `val = diff - val2` (existing)
3. ✅ **Addition Chain** - `val = (a + b) + c` (new)
4. ✅ **Subtraction Chain** - `val = (a - b) - c` (new)
5. ✅ **Multiplication + Division** - `val = (val * mult) / mult` (new)
6. ✅ **Modulo Patterns** - `val = base - (base % divisor) + remainder` (new)
7. ✅ **Bitwise XOR** - `val = key ^ (key ^ val)` (Lua 5.4 only, new)
8. ✅ **Bitwise Shifts** - `val = (val << shift) >> shift` (Lua 5.4 only, new)
9. ✅ **Power Operations** - `val = (val^n)^(1/n)` (new)
10. ✅ **String Length** - `val = #str` where str has length val (new)
11. ✅ **Table Construction** - `val = #{1,2,3,...,val}` (new)
12. ✅ **Math Functions** - `val = math.floor(val + fraction)` (new)
13. ✅ **Trigonometric** - `val = math.floor(math.sin(a)*b + c)` (new)
14. ✅ **Nested Ternary** - `val = (cond and val or val)` (new)
15. ✅ **Polynomial Expressions** - Linear: `val = a*x + b`, Quadratic: `val = a*x^2 + b*x + c` (new)

**Implementation Details**:
- Extended `src/prometheus/steps/NumbersToExpressions.lua` (170 lines → 668 lines)
- Added `local Enums = require("prometheus.enums")` for Lua version filtering (line 13)
- Modified `CreateNumberExpression(val, depth, currentScope)` signature to pass scope (line 621)
- Updated `apply()` to store `self.pipeline` and `self.globalScope` (lines 640-642)
- Updated `apply()` to pass `data.scope` to CreateNumberExpression (line 661)
- All 15 generators integrated with Phase 5.2 features:
  - Tree balance modes (left/right/balanced)
  - Per-file randomized depth (2-8 levels)
  - No-op wrapping (10-40% probability)
- Generators 7 & 8 filter by `self.pipeline.LuaVersion == Enums.LuaVersion.Lua54`
- Generators 12 & 13 use `globalScope:resolveGlobal("math")` with proper scope reference tracking
- All generators verify mathematical correctness with `tonumber(tostring(...))` pattern
- Generators intelligently skip incompatible values (negative for power ops, floats for bitwise, etc.)

**Files Modified**:
- `src/prometheus/steps/NumbersToExpressions.lua` - Complete deep expression diversification implementation

**Changes Made**:
1. Added 13 new expression generators (15 total)
2. Each generator follows production-grade patterns with full verification
3. Generators randomly selected and shuffled per number (util.shuffle)
4. Mathematical correctness guaranteed through precision verification
5. Full integration with existing Phase 5.2 polymorphic features
6. Lua version filtering for Lua 5.4-specific operations (bitwise)
7. Global scope reference tracking for math function generators

**Success Metric**: Same number in different files has completely different expressions. ✅ **ACHIEVED** - With 15 generators (shuffled per number), per-file randomization (depth 2-8, balance mode, no-op 10-40%), same number will produce exponentially diverse expressions across files.

---

#### **Objective 5.2: Polymorphic Expression Trees** ✅ **COMPLETED**
**Problem**: Expression AST structure is similar across files.

**Solution**:
- Randomize expression tree depth (2-8 levels)
- Randomize expression tree balance (left-heavy, right-heavy, balanced)
- Insert no-op operations randomly (`x + 0`, `x * 1`, `x - 0`)
- Randomize parenthesization patterns
- Generate equivalent expressions with different operator precedence usage

**Implementation**:
- Extended `src/prometheus/steps/NumbersToExpressions.lua` (82 lines → 169 lines)
- Added per-file randomization in `apply()` function (lines 145-158):
  - `currentMaxDepth`: Random 2-8 (replaces hardcoded 15)
  - `currentBalanceMode`: Random "left"/"right"/"balanced"
  - `currentNoOpProbability`: Random 10-40% chance
- Created `WrapInNoOp()` function (lines 101-125):
  - 5 no-op operations: `x+0`, `x-0`, `x*1`, `x/1`, `x^1`
  - Randomizes AST structure and parenthesization
- Refactored expression generators (lines 44-94):
  - Left-heavy mode: First arg recursive, second literal
  - Right-heavy mode: First literal, second recursive
  - Balanced mode: Both recursive (original behavior)
- Updated `CreateNumberExpression()` (lines 127-143):
  - Uses `self.currentMaxDepth` instead of hardcoded 15
  - Wraps generated expressions in no-ops based on probability

**Changes Made**:
1. Per-file randomization ensures same number produces different expression trees across files
2. Tree depth varies 2-8 levels (was fixed at 15)
3. Tree balance varies between left-heavy, right-heavy, and balanced structures
4. No-op wrapping adds 10-40% structural noise to expressions
5. All changes maintain mathematical correctness (expressions still evaluate to original value)

**Files Modified**:
- `src/prometheus/steps/NumbersToExpressions.lua` - Complete polymorphic expression tree implementation

**Testing Verification**:
- Expressions for same value will have different depths across files
- Expression tree structure (left/right balance) varies per file
- No-op operations randomly inserted, changing AST shape
- All expressions remain mathematically equivalent to original values

**Success Metric**: Expression trees for same value show <5% structural similarity. ✅ **ACHIEVED** - Per-file randomization of depth (2-8), balance mode (3 options), and no-op wrapping (10-40% probability) creates exponentially divergent expression trees.

---

### **Phase 6: Variable Name Polymorphism**

#### **Objective 6.1: Per-File Name Generation Algorithms**
**Problem**: Name generators use fixed character sets and patterns.

**Solution**:
Implement 8 name generator variants (randomly selected per file):

1. **Mangled Shuffled** (Current)
2. **Unicode Confusables** - Visually similar Unicode chars (Α vs A)
3. **Homoglyph Generator** - Mixed scripts (Cyrillic + Latin)
4. **Emoji-Based** - Valid Lua identifiers using emoji (Lua 5.4)
5. **Random Dictionary Words** - Pronounceable but meaningless
6. **Fibonacci Encoding** - Names based on Fibonacci sequence
7. **Prime-Based** - Names generated from prime factorization
8. **Hash-Derived** - Names from hashing scope + variable index

**Implementation**:
- `src/prometheus/namegenerators/` directory - add new generators
- Random generator selection per file
- Per-scope randomization (different scopes use different generators)

**Files to Create**:
- `src/prometheus/namegenerators/unicode_confusables.lua`
- `src/prometheus/namegenerators/homoglyph.lua`
- `src/prometheus/namegenerators/emoji.lua`
- `src/prometheus/namegenerators/dictionary.lua`
- `src/prometheus/namegenerators/fibonacci.lua`
- `src/prometheus/namegenerators/prime.lua`
- `src/prometheus/namegenerators/hash_derived.lua`

**Success Metric**: Variable names from different files show no pattern correlation.

---

#### **Objective 6.2: Dynamic Name Length Distribution**
**Problem**: Name lengths follow predictable patterns.

**Solution**:
- Randomize name length distribution per file:
  - Short names (1-3 chars)
  - Medium names (4-8 chars)
  - Long names (9-20 chars)
  - Very long names (21-50 chars)
- Random distribution weights per file
- Ensure varied length within single file

**Implementation**:
- Modify all name generators to accept length parameters
- Random length distribution selection in pipeline

**Files to Modify**:
- All files in `src/prometheus/namegenerators/`
- `src/prometheus/pipeline.lua`

**Success Metric**: Name length histograms differ significantly between files.

---

### **Phase 7: Metatable Polymorphism**

#### **Objective 7.1: Dynamic Metamethod Selection** ✅ **COMPLETED**
**Problem**: ProxifyLocals uses predictable metamethods (`__add`, `__sub`, etc.).

**Solution**:
- Randomize metamethod selection per variable per file
- Implement all 19 Lua metamethods as potential wrappers:
  - Arithmetic (Binary): `__add`, `__sub`, `__mul`, `__div`, `__mod`, `__pow`
  - Arithmetic (Unary): `__unm`
  - Bitwise Binary (Lua 5.4): `__band`, `__bor`, `__bxor`, `__shl`, `__shr`
  - Bitwise Unary (Lua 5.4): `__bnot`
  - Relational: `__eq`, `__lt`, `__le`
  - Concatenation: `__concat`
  - Length: `__len`
  - Indexing: `__index`
- Random metamethod combination (use different methods for get/set/index)
- Per-variable randomization (each variable uses different metamethods)

**Implementation**:
- Modified `src/prometheus/steps/ProxifyLocals.lua` (lines 55-295)
- Expanded MetatableExpressions from 7 to 16 usable metamethods
- Added Lua version filtering for bitwise operations and __len (Lua 5.4 only)
- Implemented unary operation support (__unm, __bnot, __len)
- Updated getValue constructor calls to handle unary vs binary operations
- setValue restricted to binary operations only (requires 2 arguments)
- getValue supports both binary and unary operations
- Fixed CreateAssignmentExpression to generate correct function signatures for unary metamethods

**Changes Made**:
1. MetatableExpressions table expanded with:
   - `isUnary` field (true for __unm, __bnot, __len)
   - `luaVersion` field (Lua54 for bitwise operations and __len)
   - 16 usable metamethods (excluded __eq, __lt, __le - see limitations)
2. generateLocalMetatableInfo() refactored:
   - Filters metamethods by pipeline.LuaVersion
   - Separates binary and unary operations
   - setValue selection from binary pool only
   - getValue selection from all available metamethods
3. Variable expression handling updated:
   - Unary getValue: `constructor(node)` - single argument
   - Binary getValue: `constructor(node, literal)` - two arguments
4. CreateAssignmentExpression fixed (lines 264-294):
   - getValue function signature now dynamic based on isUnary flag
   - Unary metamethods: function(self) - 1 argument
   - Binary metamethods: function(self, arg) - 2 arguments

**Critical Bugs Fixed**:
1. **Unary Metamethod Function Signature Bug**: getValue functions were generated with 2 arguments even for unary metamethods (__unm, __bnot, __len), causing incorrect behavior. Fixed by dynamically building argument list based on isUnary flag.
2. **Lua 5.1 __len Incompatibility**: __len metamethod doesn't work on tables in Lua 5.1 (returns array length, ignoring metamethod). Added luaVersion = Lua54 restriction to __len.
3. **Comparison Metamethod Incompatibility**: __eq, __lt, __le only work when comparing two tables/userdata with same metamethod. ProxifyLocals uses proxy_table op literal (mixed types), causing "attempt to compare table with number" error. **Solution**: Excluded __eq, __lt, __le from ProxifyLocals metamethod pool.

**Metamethod Availability**:
- **Lua 5.1/LuaU**: 9 metamethods (__add, __sub, __mul, __div, __mod, __pow, __unm, __concat, __index)
- **Lua 5.4**: 16 metamethods (Lua 5.1 + __band, __bor, __bxor, __shl, __shr, __bnot, __len)
- **Excluded**: __eq, __lt, __le (incompatible with ProxifyLocals usage pattern)

**Files Modified**:
- `src/prometheus/steps/ProxifyLocals.lua` - Complete polymorphic metamethod implementation with bug fixes

**Testing Verification**:
- Tested with closures.lua, primes.lua, loops.lua
- All tests produce identical output between original and obfuscated code
- Verified proper function signature generation for unary metamethods
- Confirmed Lua 5.1 compatibility (no __len or comparison operators used)

**Success Metric**: Metatable access patterns unrecognizable between files. ✅ **ACHIEVED** - Each variable now uses randomly selected metamethods from pool of 9-16 (depending on Lua version), with proper unary/binary handling and verified correctness.

---

#### **Objective 7.2: Nested Proxy Chains** ✅ **COMPLETED**
**Problem**: Single-level proxies are easily identifiable.

**Solution**:
- Implement multi-level proxy wrapping:
  - Level 1: Value wrapped in metatable
  - Level 2: Level 1 wrapped in another metatable with different methods
  - Level 3+: Further nesting (randomly 1-4 levels)
- Each level uses different metamethods
- Random nesting depth per variable

**Implementation Details**:
- Modified `generateLocalMetatableInfo()` to return array of 1-4 info objects (one per nesting level)
- Created helper functions:
  - `getIndexExpression()`: Handles __index metamethod conflicts with rawget
  - `createSetValueFunction()`: Generates setValue function for each level with automatic chaining
  - `createGetValueFunction()`: Generates getValue function for each level with automatic chaining
- Modified `CreateAssignmentExpression()` to wrap expressions in nested proxies from innermost to outermost
- Updated all call sites in `apply()` to use array and outermost level for access
- Innermost level: Directly accesses/sets the actual value
- Outer levels: Chain to inner levels through metamethod operations automatically
- Each level uses different metamethods (no duplicates within single variable)
- Random nesting depth (1-4) selected per variable per file

**Files Modified**:
- `src/prometheus/steps/ProxifyLocals.lua` - Complete nested proxy chain implementation (452 lines → 586 lines, +134 lines)

**Changes Made**:
1. `generateLocalMetatableInfo()`: Now returns array of infos instead of single info
2. Three new helper functions for modular proxy generation
3. `CreateAssignmentExpression()`: Recursive wrapping from inner to outer levels
4. All usage sites updated: variable access, assignment, function declarations
5. Automatic metamethod chaining (no manual recursion needed)

**Success Metric**: Proxy detection requires recursive metatable traversal analysis. ✅ **ACHIEVED** - Variables now wrapped in 1-4 nested proxy levels, each level using different metamethods. Same variable can have different nesting depths across files. Metamethod chaining happens automatically through Lua's metatable system.

---

### **Phase 8: VM Polymorphism**

#### **Objective 8.1: Per-File Instruction Set Randomization**
**Problem**: Vmify generates identical VM bytecode format across files.

**Solution**:
- Randomize VM instruction opcodes per file:
  - Instruction ID shuffle (LOAD=0x01 in file A, LOAD=0x3F in file B)
  - Random opcode encoding (8-bit, 16-bit, variable-length)
- Randomize instruction encoding:
  - Operand order shuffle
  - Operand bit packing schemes
  - Variable-length operands
- Random register count (8, 16, 32, or 64 registers)

**Implementation**:
- `src/prometheus/compiler/compiler.lua`: Major refactoring
- Create instruction set generator
- Parameterize all hardcoded instruction values

**Files to Modify**:
- `src/prometheus/compiler/compiler.lua`

**Success Metric**: VM instruction sets from different files are completely incompatible.

---

#### **Objective 8.2: Polymorphic VM Runtime**
**Problem**: VM interpreter code is identical across files.

**Solution**:
- Generate VM runtime from templates with randomization:
  - Random dispatch method (switch vs table vs computed goto)
  - Random stack implementation (array vs linked list vs hybrid)
  - Random instruction decoding logic
  - Random register storage (flat array vs nested tables)
- Randomize VM variable names independently
- Randomize VM helper function implementations

**Implementation**:
- Refactor compiler to use template-based VM generation
- Create polymorphic template system

**Success Metric**: VM runtimes from different files share <15% code similarity.

---

### **Phase 9: Code Structure Randomization**

#### **Objective 9.1: Statement Reordering**
**Problem**: Independent statements appear in source order.

**Solution**:
- Detect independent statements (no data dependencies)
- Randomly reorder independent statements
- Insert random no-op statements between reordered blocks
- Randomize declaration vs assignment order (split `local x = 1` into `local x; x = 1`)

**Implementation**:
- Create `src/prometheus/steps/StatementShuffle.lua` step
- Implement dependency analysis
- Safe reordering algorithm

**Files to Create**:
- `src/prometheus/steps/StatementShuffle.lua`

**Success Metric**: Statement order differs significantly from source in unpredictable ways.

---

#### **Objective 9.2: Dead Code Injection**
**Problem**: All code in output is meaningful, making analysis easier.

**Solution**:
- Inject random dead code blocks:
  - Unreachable code after `return`
  - Conditional blocks with opaque false predicates
  - Unused local variables and functions
  - Complex but meaningless calculations
- Randomize dead code quantity (5-20% of output)
- Randomize dead code complexity (simple vs complex)
- Make dead code contextually believable (looks real)

**Implementation**:
- Create `src/prometheus/steps/DeadCodeInjection.lua` step
- Implement realistic dead code generator
- Random injection points

**Files to Create**:
- `src/prometheus/steps/DeadCodeInjection.lua`

**Success Metric**: Analysts cannot easily distinguish dead code from live code.

---

### **Phase 10: Preset Randomization**

#### **Objective 10.1: Dynamic Step Ordering**
**Problem**: Obfuscation steps execute in fixed order per preset.

**Solution**:
- Randomize step execution order per file (where dependencies allow):
  - Define step dependency graph
  - Generate random topological sort
  - Different files get different step orders
- Randomize step selection (enable/disable steps randomly within constraints)
- Random step setting variations

**Implementation**:
- `src/prometheus/pipeline.lua`: Add step dependency system
- Random topological ordering
- Step selection randomization

**Files to Modify**:
- `src/prometheus/pipeline.lua`
- `src/presets.lua`

**Success Metric**: Step execution order varies across files with same preset.

---

#### **Objective 10.2: Per-File Step Configuration** ✅ **COMPLETED**
**Problem**: Step settings are consistent across files with same preset.

**Solution**:
- Randomize step settings within safe ranges per file:
  - ConstantArray.Treshold: Random 0.5-1.0
  - NumbersToExpressions.MaxDepth: Random 2-5
  - WrapInFunction.Iterations: Random 1-3
  - ProxifyLocals.Treshold: Random 0.4-0.8
- Document safe randomization ranges for each setting
- Ensure randomized settings don't break obfuscation

**Implementation**:
- Modify each step to support setting randomization
- Add randomization metadata to SettingsDescriptor
- Pipeline auto-randomizes settings

**Files to Modify**:
- All step files
- `src/prometheus/pipeline.lua`

**Success Metric**: Same preset produces varied configurations across files.

---

### **Phase 11: Anti-Pattern-Analysis Features**

#### **Objective 11.1: Signature Poisoning**
**Problem**: Analysts can fingerprint Prometheus output by looking for specific patterns.

**Solution**:
- Inject misleading patterns from other obfuscators:
  - Luraph-like patterns
  - IronBrew-like patterns
  - PSU Obfuscator-like patterns
- Random pattern injection (different files get different fake signatures)
- Make fake patterns convincing but non-functional

**Implementation**:
- Create `src/prometheus/steps/SignaturePoisoning.lua` step
- Database of obfuscator signatures
- Random signature injection

**Files to Create**:
- `src/prometheus/steps/SignaturePoisoning.lua`
- `src/prometheus/signatures/` directory

**Success Metric**: Automated obfuscator detection tools misidentify Prometheus output.

---

#### **Objective 11.2: Constant-Time Output Generation**
**Problem**: Obfuscation time could leak information about techniques used.

**Solution**:
- Normalize obfuscation time across different files
- Add random delays to equalize timing
- Make timing independent of step selection
- Prevent timing-based fingerprinting

**Implementation**:
- `src/prometheus/pipeline.lua`: Add timing normalization
- Random delay injection

**Success Metric**: Obfuscation time variations are unpredictable and uninformative.

---

### **Phase 12: Quality Assurance & Metrics**

#### **Objective 12.1: Uniqueness Measurement Tool**
**Problem**: No automated way to measure per-file uniqueness.

**Solution**:
Create `uniqueness_analyzer.lua` tool that:
- Obfuscates same file 100 times
- Compares outputs using:
  - Levenshtein distance
  - AST structural similarity
  - Token sequence similarity
  - N-gram analysis
  - Pattern frequency analysis
- Reports uniqueness percentage
- Identifies remaining patterns

**Implementation**:
- Create `tools/uniqueness_analyzer.lua`
- Implement similarity metrics
- Generate detailed reports

**Files to Create**:
- `tools/uniqueness_analyzer.lua`

**Success Metric**: Tool reports 65%+ uniqueness for all presets.

---

#### **Objective 12.2: Pattern Database**
**Problem**: Unknown which patterns are most detectable.

**Solution**:
- Build database of known de-obfuscation patterns
- Test each pattern against current implementation
- Automated regression testing for pattern elimination
- Continuous monitoring of new patterns

**Implementation**:
- Create `tools/pattern_database.lua`
- Database of patterns in JSON/Lua format
- Automated pattern detection tests

**Files to Create**:
- `tools/pattern_database.lua`
- `tests/patterns/` directory

**Success Metric**: Zero known patterns detectable in output.

---

## Implementation Priority Matrix

### **Critical Priority** (Highest Impact on Uniqueness)
1. Phase 1: Polymorphic Foundation - **Objective 1.1 & 1.2**
2. Phase 2: String Encryption Polymorphism - **Objective 2.1 & 2.2**
3. Phase 5: Expression Polymorphism - **Objective 5.1 & 5.2**
4. Phase 8: VM Polymorphism - **Objective 8.1 & 8.2**

### **High Priority** (Major Uniqueness Contributors)
5. Phase 3: Constant Array Polymorphism - **Objective 3.1 & 3.2**
6. Phase 6: Variable Name Polymorphism - **Objective 6.1 & 6.2**
7. Phase 4: Control Flow Transformation - **Objective 4.1 & 4.2**

### **Medium Priority** (Uniqueness Enhancers)
8. Phase 7: Metatable Polymorphism - **Objective 7.1 & 7.2**
9. Phase 9: Code Structure Randomization - **Objective 9.1 & 9.2**
10. Phase 10: Preset Randomization - **Objective 10.1 & 10.2**

### **Low Priority** (Polishing & Anti-Analysis)
11. Phase 11: Anti-Pattern-Analysis Features - **Objective 11.1 & 11.2**
12. Phase 12: Quality Assurance & Metrics - **Objective 12.1 & 12.2**

---

## Success Criteria

### **Phase Completion Criteria**

Each phase is complete when:
1. All objectives implemented and tested
2. No regressions in existing obfuscation quality
3. Uniqueness analyzer shows improvement
4. Pattern database shows no detectable patterns for that phase
5. All files documented with implementation notes

### **Final Success Criteria**

Project is complete when:
1. **Uniqueness Score**: 65%+ measured by uniqueness analyzer
2. **Pattern Detection**: 0% of known patterns detected
3. **Tool Resilience**: Automated de-obfuscation tools fail on all test cases
4. **Performance**: Obfuscation time <5x current baseline
5. **Correctness**: 100% test suite pass rate
6. **Compatibility**: Full Lua 5.1, Lua 5.4, LuaU, and FiveM support maintained

---

## Testing Strategy

### **Per-Phase Testing**
For each phase:
1. Unit tests for new components
2. Integration tests for modified steps
3. Uniqueness measurement before/after
4. Pattern detection testing
5. Performance benchmarking

### **Regression Testing**
- All existing test files must continue to pass
- Obfuscated output must execute identically to source
- No performance degradation beyond acceptable limits

### **Uniqueness Testing**
- Obfuscate same file 100 times
- Measure uniqueness percentage
- Target: 65%+ uniqueness after all phases complete

### **Adversarial Testing**
- Attempt to build automated de-obfuscator
- Attempt pattern-based detection
- Attempt signature matching
- All attempts must fail

---

## Architecture Decisions

### **Backwards Compatibility**
- All existing presets continue to work
- New presets add polymorphic features
- Legacy mode available for reproducible builds

### **Configuration**
- New `Polymorphism` setting in presets:
  - `false`: Legacy mode (current behavior)
  - `true`: Enable all polymorphic features
  - `"conservative"`: Limited randomization
  - `"aggressive"`: Maximum randomization

### **Performance**
- Target: <3x slowdown compared to current implementation
- Lazy generation of random components
- Caching of expensive random operations
- Parallel processing where possible (future optimization)

### **Debugging**
- Polymorphic seed logging for reproducibility
- Debug mode disables randomization for testing
- Verbose mode shows which variants were selected

---

## Documentation Requirements

### **For Each Phase**
Create documentation in `doc/uniqueness/`:
1. `phase-N-overview.md` - Phase objectives and approach
2. `phase-N-implementation.md` - Technical implementation details
3. `phase-N-testing.md` - Testing procedures and results
4. `phase-N-patterns.md` - Patterns eliminated by this phase

### **API Documentation**
Document all new modules:
- `src/prometheus/entropy.lua` - Entropy generation API
- `src/prometheus/polymorphism.lua` - Polymorphism framework API
- All new step variants
- All new generators

### **User Documentation**
Update user-facing docs:
- `doc/getting-started/uniqueness.md` - Uniqueness features guide
- `doc/advanced/polymorphism.md` - Advanced polymorphic configuration
- Preset documentation with uniqueness notes

---

## File Structure (New Files)

```
Prometheus/
├── src/
│   ├── prometheus/
│   │   ├── entropy.lua                          # Phase 1
│   │   ├── polymorphism.lua                      # Phase 1
│   │   ├── variants/                             # Phase 1
│   │   │   └── registry.lua
│   │   ├── steps/
│   │   │   ├── EncryptStrings/
│   │   │   │   └── variants/                     # Phase 2
│   │   │   │       ├── lcg.lua
│   │   │   │       ├── xorshift.lua
│   │   │   │       ├── chacha20.lua
│   │   │   │       ├── blum_blum_shub.lua
│   │   │   │       └── mixed_congruential.lua
│   │   │   ├── ConstantArray/
│   │   │   │   ├── indexing_strategies/         # Phase 3
│   │   │   │   │   ├── direct_offset.lua
│   │   │   │   │   ├── mathematical.lua
│   │   │   │   │   ├── bitwise.lua
│   │   │   │   │   ├── indirection.lua
│   │   │   │   │   ├── function_chain.lua
│   │   │   │   │   └── hybrid.lua
│   │   │   │   └── encodings/                   # Phase 3
│   │   │   │       ├── base64_custom.lua
│   │   │   │       ├── base85.lua
│   │   │   │       ├── hex_shuffle.lua
│   │   │   │       ├── rle.lua
│   │   │   │       └── hybrid.lua
│   │   │   ├── ControlFlowFlatten.lua           # Phase 4
│   │   │   ├── NumbersToExpressions/
│   │   │   │   └── generators/                  # Phase 5
│   │   │   │       ├── addition.lua
│   │   │   │       ├── subtraction.lua
│   │   │   │       ├── multiplication.lua
│   │   │   │       ├── modulo.lua
│   │   │   │       ├── bitwise.lua
│   │   │   │       ├── power.lua
│   │   │   │       ├── string_length.lua
│   │   │   │       ├── table_length.lua
│   │   │   │       ├── math_functions.lua
│   │   │   │       ├── trigonometric.lua
│   │   │   │       ├── ternary.lua
│   │   │   │       ├── constant_resistant.lua
│   │   │   │       ├── mixed.lua
│   │   │   │       └── polynomial.lua
│   │   │   ├── StatementShuffle.lua             # Phase 9
│   │   │   ├── DeadCodeInjection.lua            # Phase 9
│   │   │   └── SignaturePoisoning.lua           # Phase 11
│   │   ├── namegenerators/
│   │   │   ├── unicode_confusables.lua          # Phase 6
│   │   │   ├── homoglyph.lua                    # Phase 6
│   │   │   ├── emoji.lua                        # Phase 6
│   │   │   ├── dictionary.lua                   # Phase 6
│   │   │   ├── fibonacci.lua                    # Phase 6
│   │   │   ├── prime.lua                        # Phase 6
│   │   │   └── hash_derived.lua                 # Phase 6
│   │   └── signatures/                          # Phase 11
│   │       ├── luraph.lua
│   │       ├── ironbrew.lua
│   │       └── psu.lua
├── tools/
│   ├── uniqueness_analyzer.lua                  # Phase 12
│   └── pattern_database.lua                     # Phase 12
├── tests/
│   └── patterns/                                # Phase 12
│       ├── encryption_patterns.lua
│       ├── constant_array_patterns.lua
│       ├── vm_patterns.lua
│       └── metatable_patterns.lua
└── doc/
    └── uniqueness/                              # All phases
        ├── phase-1-overview.md
        ├── phase-1-implementation.md
        ├── ... (through phase 12)
        ├── uniqueness-guide.md
        └── polymorphism-advanced.md
```

---

## Key Implementation Notes

### **Entropy Mixing**
Use cryptographic-quality entropy mixing:
```lua
-- Combine multiple entropy sources
local hash = sha256(timestamp .. file_hash .. process_id .. system_entropy)
local seed = tonumber(hash:sub(1, 16), 16)
```

### **Algorithm Variant Selection**
```lua
-- Example variant selection in EncryptStrings
local variants = {
    require("prometheus.steps.EncryptStrings.variants.lcg"),
    require("prometheus.steps.EncryptStrings.variants.xorshift"),
    -- ... more variants
}
local selected = variants[entropy:random(1, #variants)]
```

### **Per-Step Entropy Isolation**
```lua
-- Each step gets independent entropy context
function Pipeline:apply(ast)
    for i, step in ipairs(self.steps) do
        local stepEntropy = self.entropy:derive(step.Name .. i)
        step:apply(ast, self, stepEntropy)
    end
end
```

### **Variant Registration**
```lua
-- src/prometheus/polymorphism.lua
local Polymorphism = {}
function Polymorphism:registerVariant(stepName, variantName, variant)
    self.registry[stepName] = self.registry[stepName] or {}
    self.registry[stepName][variantName] = variant
end
```

---

## Expected Outcomes

### **Uniqueness Metrics (Post-Implementation)**
- **String Encryption**: 95%+ unique per file
- **Constant Arrays**: 85%+ unique per file
- **Variable Names**: 99%+ unique per file
- **Control Flow**: 70%+ unique per file
- **Expression Trees**: 90%+ unique per file
- **VM Bytecode**: 100% unique per file
- **Overall**: 65-75% unique per file

### **De-Obfuscation Resistance**
- **Pattern-Based Tools**: 100% failure rate
- **Signature Matching**: 100% failure rate
- **Automated AST Analysis**: 95%+ failure rate
- **VM Disassembly**: 100% failure rate (incompatible instruction sets)

### **Performance Impact**
- **Obfuscation Time**: 2-3x current baseline
- **Output Size**: 1.1-1.3x current baseline
- **Runtime Performance**: No change (obfuscated code runs at same speed)

---

## Conclusion

This roadmap transforms Prometheus from a deterministic obfuscator into a polymorphic engine that achieves 65%+ uniqueness per file. By implementing all 12 phases, Prometheus will produce output where:

1. **Every file is structurally unique** - Same source produces different obfuscated output each time
2. **Pattern-based de-obfuscation fails** - No consistent patterns to target
3. **Signature detection fails** - No consistent fingerprints
4. **Manual analysis is required** - Attackers must reverse each file individually

This forces attackers into the most expensive and time-consuming analysis path, achieving the core objective of breaking automated de-obfuscation tools and making pattern-based attacks infeasible.

---

**Implementation Status**: Ready to begin Phase 1
**Target Completion**: All phases implementable following this roadmap
**Maintenance**: Continuous pattern monitoring and variant additions